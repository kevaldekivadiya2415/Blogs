{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --quiet git+https://github.com/huggingface/transformers sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from transformers import SeamlessM4TModel\n",
    "import torch\n",
    "\n",
    "# Load the pre-trained SeamlessM4T model from the ðŸ¤— Transformers Hub\n",
    "model = SeamlessM4TModel.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n",
    "\n",
    "# Check if CUDA is available, if yes, set the device to \"cuda:0\", else use the CPU\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Move the model to the specified device (CUDA if available, otherwise CPU)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary library for loading the AutoProcessor\n",
    "from transformers import AutoProcessor\n",
    "\n",
    "# Load the pre-trained SeamlessM4T medium checkpoint using the AutoProcessor\n",
    "processor = AutoProcessor.from_pretrained(\"facebook/hf-seamless-m4t-medium\")\n",
    "\n",
    "# Extracting the sample rate from the model's configuration\n",
    "sample_rate = model.config.sampling_rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech-to-Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "import torchaudio\n",
    "\n",
    "# Load the audio file\n",
    "audio_sample, audio_sampling_rate = torchaudio.load(\"/content/download.wav\")\n",
    "\n",
    "# Check if the audio's sampling rate is different from the model's sampling rate and resample if necessary\n",
    "if audio_sampling_rate != model.config.sampling_rate:\n",
    "    audio_sample = torchaudio.functional.resample(audio_sample, \n",
    "                                                  orig_freq=audio_sampling_rate, \n",
    "                                                  new_freq=model.config.sampling_rate)\n",
    "\n",
    "# Process the audio inputs using the specified processor, device, and sampling rate\n",
    "audio_inputs = processor(audios=audio_sample, return_tensors=\"pt\", sampling_rate=sample_rate).to(device)\n",
    "\n",
    "# Generate text from the processed audio inputs, targeting French as the output language and disabling speech generation\n",
    "output_tokens = model.generate(**audio_inputs, tgt_lang=\"fra\", generate_speech=False)\n",
    "\n",
    "# Decode the output tokens to obtain the translated text from the audio\n",
    "translated_text_from_audio = processor.decode(output_tokens[0].tolist()[0], skip_special_tokens=True)\n",
    "\n",
    "# Print the translated text obtained from the audio\n",
    "print(f\"Translated Text: {translated_text_from_audio}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Speech Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Audio module for displaying the generated audio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Processing the text input\n",
    "text_inputs = processor(text=\"Hello, How are you?\", src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating audio from the processed text\n",
    "audio_array_from_text = model.generate(**text_inputs, tgt_lang=\"eng\")[0].cpu().numpy().squeeze()\n",
    "\n",
    "# Displaying the generated audio using IPython's Audio function\n",
    "Audio(audio_array_from_text, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text-to-Text Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the text input\n",
    "text_inputs = processor(text=\"Hello, How are you?\", src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating text from the processed text\n",
    "text_array = model.generate(**text_inputs, tgt_lang=\"hin\", generate_speech=False)\n",
    "\n",
    "print(f\"Translated Text:- {processor.decode(text_array[0].tolist()[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Speech-to-Speech Translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "\n",
    "# Load the audio file\n",
    "audio_sample, audio_sampling_rate = torchaudio.load(\"/content/download.wav\")\n",
    "\n",
    "# Resample the audio if the sampling rate is different from the model's sampling rate\n",
    "if audio_sampling_rate != model.config.sampling_rate:\n",
    "    audio_sample = torchaudio.functional.resample(audio_sample,\n",
    "                                                  orig_freq=audio_sampling_rate,\n",
    "                                                  new_freq=model.config.sampling_rate)\n",
    "\n",
    "# Process the audio inputs\n",
    "audio_inputs = processor(audios=audio_sample, \n",
    "                         return_tensors=\"pt\",\n",
    "                         sampling_rate=sample_rate).to(device)\n",
    "\n",
    "# Generate speech from the processed audio inputs\n",
    "audio_array_from_audio = model.generate(**audio_inputs, tgt_lang=\"rus\")[0].cpu().numpy().squeeze()\n",
    "\n",
    "# Displaying the generated audio using IPython's Audio function\n",
    "Audio(audio_array_from_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tips andÂ Tricks\n",
    "\n",
    "### Use dedicated models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the SeamlessM4TForSpeechToSpeech model from the transformers library\n",
    "from transformers import SeamlessM4TForSpeechToSpeech\n",
    "\n",
    "# Load the SeamlessM4TForSpeechToSpeech model\n",
    "model = SeamlessM4TForSpeechToSpeech.from_pretrained(\"facebook/hf-seamless-m4t-medium\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify the speaker's identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchaudio\n",
    "from IPython.display import Audio\n",
    "\n",
    "# Load the audio file\n",
    "audio_sample, audio_sampling_rate = torchaudio.load(\"/content/download.wav\")\n",
    "\n",
    "# Resample the audio if the sampling rate is different from the model's sampling rate\n",
    "if audio_sampling_rate != model.config.sampling_rate:\n",
    "    audio_sample = torchaudio.functional.resample(audio_sample,\n",
    "                                                  orig_freq=audio_sampling_rate,\n",
    "                                                  new_freq=model.config.sampling_rate)\n",
    "\n",
    "# Process the audio inputs\n",
    "audio_inputs = processor(audios=audio_sample, return_tensors=\"pt\",sampling_rate=sample_rate).to(device)\n",
    "\n",
    "# Generate speech from the processed audio inputs\n",
    "audio_array_from_audio = model.generate(**audio_inputs, tgt_lang=\"rus\",spkr_id=7)[0].cpu().numpy().squeeze()\n",
    "\n",
    "# Displaying the generated audio using IPython's Audio function\n",
    "Audio(audio_array_from_audio, rate=sample_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modify generation strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the text input\n",
    "text_inputs = processor(text=\"Hello, How are you?\", src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating text from the processed text\n",
    "text_array = model.generate(**text_inputs,\n",
    "                            tgt_lang=\"hin\",\n",
    "                            generate_speech=False,\n",
    "                            text_num_beams=4,\n",
    "                            speech_do_sample=True)\n",
    "\n",
    "print(f\"Translated Text:- {processor.decode(text_array[0].tolist()[0], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leveraging Batch Processing for Enhanced Efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the text input\n",
    "text_inputs = processor(text=[\"Hello, how are you?\", \"I am fine, thank you.\"], src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating text from the processed text\n",
    "text_array = model.generate(**text_inputs,\n",
    "                            tgt_lang=\"hin\",\n",
    "                            generate_speech=False,\n",
    "                            text_num_beams=4,\n",
    "                            speech_do_sample=True)\n",
    "\n",
    "print(f\"Sentence 1:- {processor.decode(text_array[0].tolist()[0], skip_special_tokens=True)}\")\n",
    "print(f\"Sentence 2:- {processor.decode(text_array[0].tolist()[1], skip_special_tokens=True)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate both speech andÂ text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing the text input\n",
    "text_inputs = processor(text=\"Hello, How are you?\", src_lang=\"eng\", return_tensors=\"pt\").to(device)\n",
    "\n",
    "# Generating audio/text from the processed text\n",
    "audio_text_output = model.generate(**text_inputs,\n",
    "                            tgt_lang=\"rus\",\n",
    "                            text_num_beams=4,\n",
    "                            speech_do_sample=True,\n",
    "                            return_intermediate_token_ids=True)\n",
    "\n",
    "# Displaying the generated audio using IPython's Audio function\n",
    "audio_array = audio_text_output[0].cpu().numpy().squeeze()\n",
    "Audio(audio_array, rate=sample_rate)\n",
    "\n",
    "text_array = audio_text_output[2]\n",
    "translated_text_from_text = processor.decode(text_array.tolist()[0], skip_special_tokens=True)\n",
    "print(f\"Translated Text: {translated_text_from_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
